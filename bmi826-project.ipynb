{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, split, and featurize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the entire MUV dataset. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, (dataset,), transformers = dc.molnet.load_muv(featurizer=dc.feat.RawFeaturizer(smiles=True), splitter=None)\n",
    "n_tasks = len(dataset.tasks)\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, split the dataset into training and test datasets, and further split the training dataset into 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = dc.splits.RandomStratifiedSplitter()\n",
    "train_dataset, test_dataset = splitter.train_test_split(dataset, seed=826)\n",
    "train_datasets = splitter.k_fold_split(train_dataset, n_folds, seed=826)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, featurize the dataset with circular fingerprint and graph convolution featurizers. This may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(featurizer, train_datasets, test_dataset):\n",
    "    transformer = dc.trans.FeaturizationTransformer(featurizer=featurizer)\n",
    "    \n",
    "    test_dataset_featurized = transformer.transform(test_dataset)\n",
    "    train_datasets_featurized = [\n",
    "        (transformer.transform(train_dataset), transformer.transform(cv_dataset)) \n",
    "        for train_dataset, cv_dataset in train_datasets\n",
    "    ]\n",
    "    \n",
    "    return train_datasets_featurized, test_dataset_featurized\n",
    "\n",
    "\n",
    "ecfp_dataset = featurize(dc.feat.CircularFingerprint(), train_datasets, test_dataset)\n",
    "graphconv_dataset = featurize(dc.feat.ConvMolFeaturizer(), train_datasets, test_dataset)\n",
    "weave_dataset = featurize(dc.feat.WeaveFeaturizer(), train_datasets, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_task(dataset, task):\n",
    "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
    "\n",
    "\n",
    "def evaluate(dataset, model_generator, model_args):\n",
    "    scores = np.zeros((n_folds, n_tasks))\n",
    "    metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "    \n",
    "    train_datasets, test_dataset = dataset\n",
    "    \n",
    "    for fold in range(n_folds):\n",
    "        train_dataset, cv_dataset = train_datasets[fold]\n",
    "        \n",
    "        for task in range(n_tasks):\n",
    "            train_dataset_task = extract_task(train_dataset, task)\n",
    "            cv_dataset_task = extract_task(cv_dataset, task)\n",
    "            \n",
    "            m = model_generator(**model_args)\n",
    "            m.fit(train_dataset_task)\n",
    "            scores[fold, task] = m.evaluate(cv_dataset_task, [metric])['roc_auc_score']\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores = evaluate(ecfp_dataset, dc.models.SklearnModel, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-559:\n",
      "Process ForkPoolWorker-552:\n",
      "Process ForkPoolWorker-553:\n",
      "Process ForkPoolWorker-549:\n",
      "Process ForkPoolWorker-551:\n",
      "Process ForkPoolWorker-556:\n",
      "Process ForkPoolWorker-554:\n",
      "Process ForkPoolWorker-548:\n",
      "Process ForkPoolWorker-555:\n",
      "Process ForkPoolWorker-557:\n",
      "Process ForkPoolWorker-560:\n",
      "Process ForkPoolWorker-550:\n",
      "Process ForkPoolWorker-558:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34644/247745445.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m rf_scores = pool.starmap(evaluate, [(ecfp_dataset, dc.models.SklearnModel, model_args) \n\u001b[0;32m---> 19\u001b[0;31m                                     for model_args in rf_model_args])\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         '''\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-542:\n",
      "Process ForkPoolWorker-532:\n",
      "Process ForkPoolWorker-545:\n",
      "Process ForkPoolWorker-525:\n",
      "Process ForkPoolWorker-534:\n",
      "Process ForkPoolWorker-523:\n",
      "Process ForkPoolWorker-531:\n",
      "Process ForkPoolWorker-521:\n",
      "Process ForkPoolWorker-528:\n",
      "Process ForkPoolWorker-539:\n",
      "Process ForkPoolWorker-547:\n",
      "Process ForkPoolWorker-535:\n",
      "Process ForkPoolWorker-537:\n",
      "Process ForkPoolWorker-533:\n",
      "Process ForkPoolWorker-530:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-536:\n",
      "Process ForkPoolWorker-538:\n",
      "Process ForkPoolWorker-544:\n",
      "Process ForkPoolWorker-543:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-546:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/utils/data_utils.py\", line 500, in load_from_disk\n",
      "    return np.load(filename, allow_pickle=True)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 441, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "Process ForkPoolWorker-529:\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/numpy/lib/format.py\", line 757, in read_array\n",
      "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-526:\n",
      "Process ForkPoolWorker-522:\n",
      "Process ForkPoolWorker-524:\n",
      "Process ForkPoolWorker-540:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-541:\n",
      "Process ForkPoolWorker-527:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 15, in evaluate\n",
      "    train_dataset_task = extract_task(train_dataset, task)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/tmp/ipykernel_34644/574081408.py\", line 2, in extract_task\n",
      "    return dc.data.NumpyDataset(dataset.X, dataset.y[:, task], dataset.w[:, task], dataset.ids)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2428, in X\n",
      "    for (X_b, _, _, _) in self.itershards():\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 1528, in <genexpr>\n",
      "    return (self.get_shard(i) for i in range(self.get_number_shards()))\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/data/datasets.py\", line 2102, in get_shard\n",
      "    X = np.array(load_from_disk(os.path.join(self.data_dir, row['X'])))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "rf_n_estimators = [1000, 4000, 16000]\n",
    "rf_max_features = [None, 'sqrt', 'log2']\n",
    "rf_class_weight = [None, 'balanced', 'balanced_subsample']\n",
    "\n",
    "rf_model_args = [\n",
    "    {\n",
    "        'model': RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                        max_features=max_features, \n",
    "                                        class_weight=class_weight)\n",
    "    }\n",
    "    for n_estimators in rf_n_estimators\n",
    "    for max_features in rf_max_features\n",
    "    for class_weight in rf_class_weight\n",
    "]\n",
    "\n",
    "rf_scores = [(model_args, evaluate(ecfp_dataset, dc.models.SklearnModel, model_args))\n",
    "             for model_args in rf_model_args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Reshape_14:0\", shape=(375,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Reshape_13:0\", shape=(375, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Reshape_17:0\", shape=(2598,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Reshape_16:0\", shape=(2598, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Reshape_20:0\", shape=(2253,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Reshape_19:0\", shape=(2253, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Reshape_23:0\", shape=(124,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Reshape_22:0\", shape=(124, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_15/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_11:0\", shape=(375,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_10:0\", shape=(375, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_13:0\", shape=(2598,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_12:0\", shape=(2598, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_15:0\", shape=(2253,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_14:0\", shape=(2253, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_17:0\", shape=(124,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_16:0\", shape=(124, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_conv_15/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Reshape_14:0\", shape=(375,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Reshape_13:0\", shape=(375, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Reshape_17:0\", shape=(2598,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Reshape_16:0\", shape=(2598, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Reshape_20:0\", shape=(2253,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Reshape_19:0\", shape=(2253, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Reshape_23:0\", shape=(124,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Reshape_22:0\", shape=(124, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model_7/graph_pool_14/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "Process ForkPoolWorker-1508:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "_pickle.UnpicklingError: invalid load key, '?'.\n",
      "Process ForkPoolWorker-1509:\n",
      "_pickle.UnpicklingError: invalid load key, '\\x00'.\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-1514:\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "_pickle.UnpicklingError: invalid load key, '\\x00'.\n",
      "Process ForkPoolWorker-1529:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_pickle.UnpicklingError: invalid load key, '?'.\n",
      "Process ForkPoolWorker-1619:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "_pickle.UnpicklingError: invalid load key, '?'.\n",
      "Process ForkPoolWorker-1709:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "_pickle.UnpicklingError: invalid load key, '?'.\n",
      "Process ForkPoolWorker-1799:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "_pickle.UnpicklingError: invalid load key, '?'.\n",
      "Process ForkPoolWorker-1800:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "_pickle.UnpicklingError: invalid load key, '\\x00'.\n",
      "Process ForkPoolWorker-1830:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/users/gaffneyk/miniconda3/envs/bmi826-project/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "_pickle.UnpicklingError: invalid load key, '\\x00'.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34644/1924427522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m scores = [(model_args, evaluate(graphconv_dataset, dc.models.GraphConvModel, model_args))\n\u001b[0;32m---> 13\u001b[0;31m            for model_args in gc_model_args]\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_34644/1924427522.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m scores = [(model_args, evaluate(graphconv_dataset, dc.models.GraphConvModel, model_args))\n\u001b[0;32m---> 13\u001b[0;31m            for model_args in gc_model_args]\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_34644/574081408.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataset, model_generator, model_args)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_dataset_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roc_auc_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             deterministic=deterministic), max_checkpoints_to_keep,\n\u001b[0;32m--> 324\u001b[0;31m         checkpoint_interval, restore, variables, loss, callbacks, all_losses)\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m   def fit_generator(self,\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m       \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_gradient_for_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m       \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/bmi826-project/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gc_model_args = [\n",
    "    {\n",
    "        'n_tasks': 1,\n",
    "        'graph_conv_layers': layers[:-1],\n",
    "        'dense_layer_size': layers[-1],\n",
    "        'dropout': dropout\n",
    "    }\n",
    "    for layers in [[64, 64, 128], [128, 128, 256], [256, 256, 512]]\n",
    "    for dropout in [0.0, 0.1, 0.2]\n",
    "]\n",
    "\n",
    "gc_scores = [(model_args, evaluate(graphconv_dataset, dc.models.GraphConvModel, model_args))\n",
    "             for model_args in gc_model_args]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
